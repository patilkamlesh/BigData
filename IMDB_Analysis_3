import java.io.IOException;
import java.util.Map.Entry;
import java.util.Stack;
import java.util.TreeMap;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.conf.*;
import org.apache.hadoop.io.*;
import org.apache.hadoop.mapreduce.*;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.io.DoubleWritable;
        
public class Problem3 {
        
 public static class Map extends Mapper<LongWritable, Text, Text, DoubleWritable> {
     private Text word = new Text();
        
    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
    	String line = value.toString();
        String[] scannedArray = line.split("::");
        String zipCodeString = scannedArray[4];
        Integer ageOfPerson = Integer.parseInt(scannedArray[2]);
        DoubleWritable ageOfPersonDoW = new DoubleWritable(ageOfPerson);
        word.set(zipCodeString); 
        context.write(word,ageOfPersonDoW);
     }
 } 
        
 public static class Reduce extends Reducer<Text, DoubleWritable, Text, DoubleWritable> {

    public void reduce(Text key, Iterable<DoubleWritable> values, Context context) 
      throws IOException, InterruptedException {
        Double sum =  (double) 0;
        Double noOfPeople = (double) 0;
        /*In this section, we are calculating average age for each and every Zip code*/
        
        for (DoubleWritable val : values) {
        	noOfPeople = noOfPeople + 1;
        	sum += val.get();
          }
        Double avgofPeople = sum/noOfPeople;
        DoubleWritable avgofPeopleDW = new DoubleWritable(avgofPeople);
        
        /*This section is used to emit the Zip code and corresponding average age*/
        
        context.write(key,avgofPeopleDW);   	
        
    }
 }
 

        /*Following sections contains programming for second mapper-reducer*/
 
 public static class TopTenMapper extends Mapper<LongWritable, Text, Text, Text> {
	 
	 private TreeMap<String, Text> repToRecordMap = new TreeMap<String, Text>();
	 Double scanArrAvg;
	 Text myAvg;
	
	 
	 public void map(LongWritable key, Text value, Context context)
			 throws IOException, InterruptedException {
		 
		    /*This section is used to read zip codes and corresponding average age values from the output file
		     *generated by first reducer */		    
		 
		    String line = value.toString();
	        String[] scannedArray = line.split("\t");
	        String modifiedKey;
	        
	        /*This section is used appropriate formatting of average age together with zip code
	         *so that it can be concatenated together and then be used for sorting  */
	        
	        modifiedKey = formattedKey(scannedArray[1].toString(),scannedArray[0].toString());
		    scanArrAvg = Double.parseDouble((scannedArray[1].toString())) ;
		    myAvg = new Text();
		    myAvg.set(scanArrAvg.toString());	
		    
		 	/*Following section is used to add the concatenated key to tree map */
		    
		    repToRecordMap.put(modifiedKey,new Text(scannedArray[0].toString()));
			 
			 if (repToRecordMap.size() > 10) {
				 repToRecordMap.remove(repToRecordMap.lastKey());
			 	}
	 
            }
	 
	
	 /*This method is used to format the average and zip code into appropriate from so that it can be used for sorting*/
	 
	 public String formattedKey(String avg, String zip){
		 StringBuffer zero=new StringBuffer("0");
		 StringBuffer number=new StringBuffer(avg);
		 if(avg.charAt(1)=='.'){
		 zero.append(number);
		 number=zero;
		 if(number.length()<=5){
		 number.append("00");
		 }
		 }
		 String numberToReturn=(String) number.subSequence(0, 4);
		 return numberToReturn+zip;
		 }
	 
	 /*This section is used to emit the intermediate key-value pair which then can be used by second reducer*/
	 
	 protected void cleanup(Context context) throws IOException, InterruptedException 
     {
     
     for (Entry<String,Text> t : repToRecordMap.entrySet() ) 
     	{
    	 context.write(new Text(t.getKey()),new Text(t.getValue()));
    	 }
     }
	 
	 
	 
 }
 
 public static class TopTenReducer extends  Reducer<Text, Text, Text, Text> {
	
	  TreeMap<String, String> repToRecordRed = new TreeMap<String, String>();
		 Stack<String[]> stackforAvg=new Stack<String[]>();
		 
		 
		 public void reduce(Text key, Iterable<Text> values, Context context) 
		 throws IOException, InterruptedException {
		  /*In this section, we are adding each and every value that we get from the mappers and sort them accordingly*/
			 
		 for (Text text : values) {
		 	 repToRecordRed.put((key.toString()),text.toString());
			 if (repToRecordRed.size() > 10) {repToRecordRed.remove(repToRecordRed.lastKey());
			 }			 		 
		 }
		 }
		 
		 
		 /*This section is used insert sorted average values into the stack and then retrieve them so that 
		  *we get youngest average in descending order */
		 
		 public void cleanup(Context context) throws IOException, InterruptedException {
			for (Entry<String,String> t : repToRecordRed.entrySet() ) 
		     	{
				String[] finalReduceString = new String [2];
		    	 finalReduceString[0] = t.getValue();
				 finalReduceString[1]=t.getKey().substring(0, 4);
				 stackforAvg.push(finalReduceString);
		     	}			 
			 			 
			 while(!stackforAvg.isEmpty()){
				 String[] keyValueToWrite=stackforAvg.pop();
				 String zip=keyValueToWrite[0];
				 String ageString=keyValueToWrite[1];
				 Double age=Double.parseDouble(ageString);
				 context.write(new Text(zip), new Text(age.toString()));
				 }
			 }	
	 }
 
 

        
 public static void main(String[] args) throws Exception {

	 
    Configuration conf = new Configuration();        
    Job job = new Job(conf, "useraveragecount");
    
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(DoubleWritable.class);
    
    job.setJarByClass(Problem3.class);
    job.setMapperClass(Map.class);
    job.setCombinerClass(Reduce.class);
    job.setReducerClass(Reduce.class);
        
    job.setInputFormatClass(TextInputFormat.class);
    job.setOutputFormatClass(TextOutputFormat.class);
        
    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));
        
    job.waitForCompletion(true);
    
    /*Wait for the map-reduce job to complete and then start the second map-reduce job*/
    
    if(job.isComplete()){
    	Configuration conftwo = new Configuration(); 
    	
    	Job jobtwo = new Job(conftwo, "secondjob");
    	
    	jobtwo.setOutputKeyClass(Text.class);
    	jobtwo.setOutputValueClass(Text.class);
    	
        jobtwo.setJarByClass(Problem3.class);
        jobtwo.setMapperClass(TopTenMapper.class);
        jobtwo.setReducerClass(TopTenReducer.class);
        
        jobtwo.setInputFormatClass(TextInputFormat.class);
        jobtwo.setOutputFormatClass(TextOutputFormat.class);
        
        FileInputFormat.addInputPath(jobtwo, new Path(args[1]));
        FileOutputFormat.setOutputPath(jobtwo, new Path(args[2]));
        
        jobtwo.waitForCompletion(true);
    	
    }
 }
        
}
